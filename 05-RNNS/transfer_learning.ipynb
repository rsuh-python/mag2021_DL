{"cells":[{"cell_type":"markdown","metadata":{"id":"6sR9QjWDQEZ6"},"source":["# Transfer Learning & Fine-tuning"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LGB-rJkbQEZ7"},"outputs":[],"source":["import glob\n","import sys\n","import warnings\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import torch\n","import torch.nn.functional as F\n","from torch import nn\n","from tqdm.auto import tqdm\n","\n","\n","%matplotlib inline\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","metadata":{"id":"9zuAlKtqQEZ8"},"source":["# Transfer learning\n","\n","На этом семинаре мы научимся очень быстро обучать нейросеть на сложную задачу классификации изображений, используя очень простой приём, именуемый fine tuning'ом. \n","\n","Для начала скачаем датасет. На этот раз мы научим нейронку отличать кошечек от собачек."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2jNqmVORQEZ9"},"outputs":[],"source":["!wget https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip && unzip kagglecatsanddogs_5340.zip > /dev/null"]},{"cell_type":"markdown","metadata":{"id":"p0bVe6foQEZ9"},"source":["Удалим несколько битых изображений"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UMVKmldZQEZ-"},"outputs":[],"source":["!rm -rf ./PetImages/Cat/666.jpg ./PetImages/Dog/11702.jpg"]},{"cell_type":"markdown","metadata":{"id":"N8pZww-rQEZ-"},"source":["Датасет разделим средствами pytorch'a на трейн и тест."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Am9UgGUwQEZ_"},"outputs":[],"source":["from torchvision.datasets import ImageFolder\n","from torchvision.transforms import Compose, Normalize, Resize, ToTensor \n","\n","dataset = ImageFolder(\n","    \"./PetImages\", \n","    transform=Compose(\n","        [\n","            Resize((224, 224)), \n","            ToTensor(), \n","            Normalize((0.5, 0.5, 0.5), (1, 1, 1)), \n","        ]\n","    )\n",")\n","train_set, test_set = torch.utils.data.random_split(\n","    dataset, \n","    [int(0.8 * len(dataset)), len(dataset) - int(0.8 * len(dataset))]\n",")"]},{"cell_type":"markdown","metadata":{"id":"KImCi0emQEZ_"},"source":["Сделаем из скачанных датасетов даталоадеры"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uljsqCQXQEaA"},"outputs":[],"source":["train_dataloader = torch.utils.data.DataLoader(train_set, batch_size=256, shuffle=True)\n","test_dataloader = torch.utils.data.DataLoader(test_set, batch_size=256, shuffle=False)"]},{"cell_type":"markdown","metadata":{"id":"d_Z3mwchQEaA"},"source":["Посмотрим, как выглядят картинки."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O45fIlNuQEaA"},"outputs":[],"source":["file = np.random.choice(glob.glob(\"./PetImages/*/*.jpg\"))\n","plt.imshow(plt.imread(file));"]},{"cell_type":"markdown","metadata":{"id":"ItwVf1FIQEaB"},"source":["## Fine-Tuning"]},{"cell_type":"markdown","metadata":{"id":"ihpGfLjqQEaC"},"source":["Кошки и собаки это конечно хорошо, вот только обучение модели, которая будет хорошо работать на этом датасете может оказаться очень долгим...\n","\n","Однако картинки, которые мы сегодня рассмотрим оказываются очень похожими на картинки из огромного датасета ImageNet. Задача, которую мы сегодня рассмотрим, называется Transfer Learning -- в русскоязычной литературе иногда можно встретить термин \"обучение с переносом знаний\". Знания мы действительно переносим -- от сети, которая хорошо работает на одном датасете (ImageNet) к другим данным (к датасету Cats vs Dogs)."]},{"cell_type":"markdown","metadata":{"id":"OfNvcOXgQEaC"},"source":["### Загрузим уже обученную сеть\n","\n","В библиотеке `torchvision` имплементировано не только большое множество моделей (всевозможные ResNet'ы, Inception, VGG, AlexNet, DenseNet, ResNext, WideResNet, MobileNet...), но и загружены чекпоинты обучения этих моделей на ImageNet. Однако для датасета Cats vs Dogs такая штука является роскошью..."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vxMgp8NeQEaC"},"outputs":[],"source":["from torchvision.models import resnet18\n","\n","# Загрузить предобученную сеть -- pretrained=True\n","model = resnet18(pretrained=True)\n","model"]},{"cell_type":"markdown","source":["Пара слов о resnet:\n","\n","В очень глубоких сетках есть такая проблема, связанная с затуханием градиентов (если у нас слишком много слоев, градиентам приходится течь далеко, и они могут понемногу занулиться). Для решения этой проблемы придумали такую архитектуру, которая не только передает градиенты обычным способом, но и пробрасывает их без изменений через слои, то есть, выглядит это все примерно так:\n","\n","\n","<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/5/5f/ResNets.svg/1200px-ResNets.svg.png\" width=\"300\"/>\n","\n","Такие вот пробросы называются skip connections. "],"metadata":{"id":"Bwi7PE6ujvRj"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"hIf1fdf-QEaD"},"outputs":[],"source":["for param in model.parameters():\n","    param.requires_grad = False"]},{"cell_type":"markdown","metadata":{"id":"kapc805MQEaD"},"source":["В задаче transfer learning'a мы заменяем последний слой нейросети на линейный с двумя выходами."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wjs32xa5QEaD"},"outputs":[],"source":["model.fc = nn.Linear(512, 2)"]},{"cell_type":"markdown","metadata":{"id":"aMzg8uKfQEaD"},"source":["Ниже несколько функций, которые мы накопипастили из предыдущих тетрадок."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V3JuPsJRQEaD"},"outputs":[],"source":["def train_epoch(\n","    model,\n","    data_loader,\n","    optimizer,\n","    criterion,\n","    return_losses=False,\n","    device=\"cuda:0\",\n","):\n","    model = model.to(device).train()\n","    total_loss = 0\n","    num_batches = 0\n","    all_losses = []\n","    total_predictions = np.array([])#.reshape((0, ))\n","    total_labels = np.array([])#.reshape((0, ))\n","    with tqdm(total=len(data_loader), file=sys.stdout) as prbar:\n","        for images, labels in data_loader:\n","            # Move Batch to GPU\n","            images = images.to(device)\n","            labels = labels.to(device)\n","            predicted = model(images)\n","            loss = criterion(predicted, labels)\n","            # Update weights\n","            loss.backward()\n","            optimizer.step()\n","            optimizer.zero_grad()\n","            # Update descirption for tqdm\n","            accuracy = (predicted.argmax(1) == labels).float().mean()\n","            prbar.set_description(\n","                f\"Loss: {round(loss.item(), 4)} \"\n","                f\"Accuracy: {round(accuracy.item() * 100, 4)}\"\n","            )\n","            prbar.update(1)\n","            total_loss += loss.item()\n","            total_predictions = np.append(total_predictions, predicted.argmax(1).cpu().detach().numpy())\n","            total_labels = np.append(total_labels, labels.cpu().detach().numpy())\n","            num_batches += 1\n","            all_losses.append(loss.detach().item())\n","    metrics = {\"loss\": total_loss / num_batches}\n","    metrics.update({\"accuracy\": (total_predictions == total_labels).mean()})\n","    if return_losses:\n","        return metrics, all_losses\n","    else:\n","        return metrics\n","\n","\n","def validate(model, data_loader, criterion, device=\"cuda:0\"):\n","    model = model.eval()\n","    total_loss = 0\n","    num_batches = 0\n","    total_predictions = np.array([])\n","    total_labels = np.array([])\n","    with tqdm(total=len(data_loader), file=sys.stdout) as prbar:\n","        for images, labels in data_loader:\n","            images = images.to(device)\n","            labels = labels.to(device)\n","            predicted = model(images)\n","            loss = criterion(predicted, labels)\n","            accuracy = (predicted.argmax(1) == labels).float().mean()\n","            prbar.set_description(\n","                f\"Loss: {round(loss.item(), 4)} \"\n","                f\"Accuracy: {round(accuracy.item() * 100, 4)}\"\n","            )\n","            prbar.update(1)\n","            total_loss += loss.item()\n","            total_predictions = np.append(total_predictions, predicted.argmax(1).cpu().detach().numpy())\n","            total_labels = np.append(total_labels, labels.cpu().detach().numpy())\n","            num_batches += 1\n","    metrics = {\"loss\": total_loss / num_batches}\n","    metrics.update({\"accuracy\": (total_predictions == total_labels).mean()})\n","    return metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5AqpAGyFQEaE"},"outputs":[],"source":["def fit(\n","    model,\n","    epochs,\n","    train_data_loader,\n","    validation_data_loader,\n","    optimizer,\n","    criterion,\n","    device=\"cuda:0\"\n","):\n","    all_train_losses = []\n","    epoch_train_losses = []\n","    epoch_eval_losses = []\n","    for epoch in range(epochs):\n","        # Train step\n","        print(f\"Train Epoch: {epoch}\")\n","        train_metrics, one_epoch_train_losses = train_epoch(\n","            model=model,\n","            data_loader=train_data_loader,\n","            optimizer=optimizer,\n","            return_losses=True,\n","            criterion=criterion,\n","            device=device\n","        )\n","        # Save Train losses\n","        all_train_losses.extend(one_epoch_train_losses)\n","        epoch_train_losses.append(train_metrics[\"loss\"])\n","        # Eval step\n","        print(f\"Validation Epoch: {epoch}\")\n","        with torch.no_grad():\n","            validation_metrics = validate(\n","                model=model,\n","                data_loader=validation_data_loader,\n","                criterion=criterion\n","            )\n","        # Save eval losses\n","        epoch_eval_losses.append(validation_metrics[\"loss\"])"]},{"cell_type":"markdown","metadata":{"id":"HY-5mzZTQEaE"},"source":["Создайте объект лосса и оптимизатор."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p5Oh5Y8hQEaE"},"outputs":[],"source":["criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.fc.parameters(), 1e-4)\n","device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hjf2g663QEaE","scrolled":true},"outputs":[],"source":["fit(model, 5, train_dataloader, test_dataloader, optimizer, criterion, device=device)"]},{"cell_type":"markdown","metadata":{"id":"YPk6WiNrQEaE"},"source":["Как видим на одну эпоху обучения уходит порядка двух минут, и уже после одной эпохи получается приемлемое качество. Давайте проинициализируем модель с нуля и попробуем обучить."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IRjGr6SPQEaF"},"outputs":[],"source":["model_full = resnet18(pretrained=False)\n","model_full.fc = nn.Linear(512, 2)\n","optimizer = torch.optim.Adam(model.parameters(), 1e-4)  # YOUR CODE. It must optimize across all parameters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0Fr3dCIZQEaF","scrolled":true},"outputs":[],"source":["fit(model_full, 5, train_dataloader, test_dataloader, optimizer, criterion, device=device)"]},{"cell_type":"markdown","metadata":{"id":"Xr5TLEA2QEaF"},"source":["__Вопрос__. Почему при обучении полной модели получается так, что время на одну эпоху почти такое же?\n","\n","Рекомендуем подумать на этим вопросом самостоятельно."]},{"cell_type":"markdown","metadata":{"id":"F7sQEUbPQEaF"},"source":["Как мы видим, на transfer learning'e нейросеть сходится очень быстро. Значительно быстрее, чем инициализированная с нуля. Можно с уверенностью говорить, что transfer learning -- очень полезная техника."]},{"cell_type":"markdown","source":["Еще примеры файнтьюнинга можно посмотреть в [этой статье](https://medium.com/@abhi1thakur/fine-tuning-for-image-classification-using-pytorch-81e77d125646). "],"metadata":{"id":"inEqaJsXlph8"}}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":0}