{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OE7fXh-OSJYF",
    "outputId": "7a8589d7-dea3-4959-a52e-a75b323dbda3"
   },
   "outputs": [],
   "source": [
    "!pip -qq install torch\n",
    "!pip -qq install torchtext\n",
    "!pip -qq install spacy\n",
    "!python -m spacy download en_core_web_sm\n",
    "!pip -qq install sacremoses==0.0.5\n",
    "!pip -qq install subword_nmt==0.3.5\n",
    "!wget http://www.manythings.org/anki/rus-eng.zip \n",
    "!unzip rus-eng.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uhvfH55PUJ8K"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    from torch.cuda import FloatTensor, LongTensor\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    from torch import FloatTensor, LongTensor\n",
    "    DEVICE = torch.device('cpu')\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "txWqIO_74A4s"
   },
   "source": [
    "# Machine Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyNkst1XkYN6"
   },
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tRLNIzJkkqkM"
   },
   "source": [
    "Начнем с чтения данных. Возьмем их у anki, поэтому они немного специфичны:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PBRzeyT_sw1t",
    "outputId": "a81a5f78-1578-413b-dfb2-5976d28ba787"
   },
   "outputs": [],
   "source": [
    "!shuf -n 10 rus.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QOVlO5_Qlg5y"
   },
   "source": [
    "Токенизируем их:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fsOvtO0fpCHa",
    "outputId": "c214ac38-53c3-43f6-a0cd-d4bae7625269"
   },
   "outputs": [],
   "source": [
    "from torchtext.legacy.data import Field, Example, Dataset, BucketIterator\n",
    "\n",
    "BOS_TOKEN = '<s>'\n",
    "EOS_TOKEN = '</s>'\n",
    "\n",
    "source_field = Field(tokenize='spacy', init_token=None, eos_token=EOS_TOKEN)\n",
    "target_field = Field(tokenize='moses', init_token=BOS_TOKEN, eos_token=EOS_TOKEN)\n",
    "fields = [('source', source_field), ('target', target_field)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0qA15-tcudjw",
    "outputId": "d744840b-6309-41df-d533-40cdcb17c8fd"
   },
   "outputs": [],
   "source": [
    "source_field.preprocess(\"It's surprising that you haven't heard anything about her wedding.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HguPFHc5sjcD",
    "outputId": "983cf4ea-a0c9-4204-d6fb-d56ed3e59b37"
   },
   "outputs": [],
   "source": [
    "target_field.preprocess('Удивительно, что ты ничего не слышал о её свадьбе.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VO-gix7yoBjg",
    "outputId": "bc153071-bdda-4571-8a1e-f92f7de64315"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "MAX_TOKENS_COUNT = 16\n",
    "SUBSET_SIZE = .3\n",
    "\n",
    "examples = []\n",
    "with open('rus.txt', encoding='utf8') as f:\n",
    "    for line in tqdm(f, total=440219):\n",
    "        source_text, target_text, _ = line.split('\\t')\n",
    "        source_text = source_field.preprocess(source_text)\n",
    "        target_text = target_field.preprocess(target_text)\n",
    "        if len(source_text) <= MAX_TOKENS_COUNT and len(target_text) <= MAX_TOKENS_COUNT:\n",
    "            if np.random.rand() < SUBSET_SIZE:\n",
    "                examples.append(Example.fromlist([source_text, target_text], fields))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A8uCsMEglm6V"
   },
   "source": [
    "Построим датасеты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZOBgLAgVTrk1",
    "outputId": "9b5b3c3f-32ee-452f-8abd-c072b78c9115"
   },
   "outputs": [],
   "source": [
    "dataset = Dataset(examples, fields)\n",
    "\n",
    "train_dataset, test_dataset = dataset.split(split_ratio=0.85)\n",
    "\n",
    "print('Train size =', len(train_dataset))\n",
    "print('Test size =', len(test_dataset))\n",
    "\n",
    "source_field.build_vocab(train_dataset, min_freq=3)\n",
    "print('Source vocab size =', len(source_field.vocab))\n",
    "\n",
    "target_field.build_vocab(train_dataset, min_freq=3)\n",
    "print('Target vocab size =', len(target_field.vocab))\n",
    "\n",
    "train_iter, test_iter = BucketIterator.splits(\n",
    "    datasets=(train_dataset, test_dataset), batch_sizes=(32, 256), shuffle=True, device=DEVICE, sort=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N5sMz-hfBvCl",
    "outputId": "8625bee5-bb43-402f-cb56-ccf780cf9bda"
   },
   "outputs": [],
   "source": [
    "source_field.process([source_field.preprocess(\"It's surprising that you haven't heard anything about her wedding.\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M1yFzRg2xAjl"
   },
   "outputs": [],
   "source": [
    "source_field.vocab.itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "19X2G_QpxJEx"
   },
   "outputs": [],
   "source": [
    "target_field.vocab.itos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8FYJe2CA8GcY"
   },
   "source": [
    "## Seq2seq модель\n",
    "\n",
    "Пора писать простой seq2seq. Разобьем модель на несколько модулей - Encoder, Decoder и их объединение. \n",
    "\n",
    "Encoder должен быть подобен символьной сеточке в POS tagging'е: эмбеддить токены и запускать rnn'ку (в данном случае будем пользоваться GRU) и отдавать последнее скрытое состояние.\n",
    "\n",
    "Decoder почти такой же, только еще и предсказывает токены на каждом своем шаге.\n",
    "\n",
    "**Задание** Реализовать модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ySJ4tUAqvFvB"
   },
   "outputs": [],
   "source": [
    "batch = next(iter(train_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x8ndCRZLl4ZZ"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim=128, rnn_hidden_dim=256, num_layers=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self._bidir = False\n",
    "        self._num_layers = num_layers\n",
    "        self._hidden_dim = rnn_hidden_dim // 2 if self._bidir else rnn_hidden_dim\n",
    "        \n",
    "        self._emb = nn.Embedding(vocab_size, emb_dim)\n",
    "        self._rnn = nn.GRU(input_size=emb_dim, hidden_size=self._hidden_dim, \n",
    "                           num_layers=num_layers, bidirectional=self._bidir, dropout=0.2)\n",
    "\n",
    "    def forward(self, inputs, hidden=None):\n",
    "        # ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Un0AOmdqLPp_"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim=128, rnn_hidden_dim=256, num_layers=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self._emb = nn.Embedding(vocab_size, emb_dim)\n",
    "        self._rnn = nn.GRU(input_size=emb_dim, hidden_size=rnn_hidden_dim, num_layers=num_layers)\n",
    "        self._out = nn.Linear(rnn_hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, inputs, hidden=None):\n",
    "        # ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n9nsO1HCmgn3"
   },
   "source": [
    "Модель перевода будет просто сперва вызывать Encoder, а потом передавать его скрытое состояние декодеру в качестве начального."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vLIGjPOiO7X9"
   },
   "outputs": [],
   "source": [
    "class TranslationModel(nn.Module):\n",
    "    def __init__(self, source_vocab_size, target_vocab_size, emb_dim=128, \n",
    "                 rnn_hidden_dim=256, encoder_layers=2, decoder_layers=1):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = Encoder(source_vocab_size, emb_dim, rnn_hidden_dim, num_layers=encoder_layers)\n",
    "        self.decoder = Decoder(target_vocab_size, emb_dim, rnn_hidden_dim, num_layers=decoder_layers)\n",
    "        \n",
    "    def forward(self, source_inputs, target_inputs):\n",
    "        encoder_hidden = self.encoder(source_inputs)\n",
    "        \n",
    "        return self.decoder(target_inputs, encoder_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5_qVuSL8QJg4",
    "outputId": "37b94aad-78b5-46dc-d174-25f157104bcd"
   },
   "outputs": [],
   "source": [
    "model = TranslationModel(source_vocab_size=len(source_field.vocab), target_vocab_size=len(target_field.vocab),\n",
    "                        encoder_layers=2).to(DEVICE)\n",
    "\n",
    "outs = model(batch.source, batch.target)\n",
    "outs[0].shape, outs[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pz4Ckgh1mwm4"
   },
   "source": [
    "Реализуем простой перевод - жадный. На каждом шаге будем выдавать самый вероятный из предсказываемых токенов:\n",
    "\n",
    "![](https://github.com/tensorflow/nmt/raw/master/nmt/g3doc/img/greedy_dec.jpg)  \n",
    "*From [tensorflow/nmt](https://github.com/tensorflow/nmt)*\n",
    "\n",
    "**Задание** Реализовать функцию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h9gmcOC9DwiS"
   },
   "outputs": [],
   "source": [
    "def greedy_decode(model, source_text, source_field, target_field):\n",
    "    bos_index = target_field.vocab.stoi[BOS_TOKEN]\n",
    "    eos_index = target_field.vocab.stoi[EOS_TOKEN]\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        result = [] # list of predicted tokens indices\n",
    "        # ???\n",
    "            \n",
    "        return ' '.join(target_field.vocab.itos[ind.squeeze().item()] for ind in result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "mM58pAd6FBml",
    "outputId": "4aaa48f4-c4a3-409f-daa0-72b7f648d24e"
   },
   "outputs": [],
   "source": [
    "greedy_decode(model, \"Do you believe?\", source_field, target_field)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0-ha7DI_ngAO"
   },
   "source": [
    "Нужно как-то оценивать модель.\n",
    "\n",
    "Обычно для этого используется [BLEU скор](https://en.wikipedia.org/wiki/BLEU) - что-то вроде точности угадывания n-gram из правильного (референсного) перевода.\n",
    "\n",
    "**Задание** Реализовать функцию оценки: для батчей из `iterator` предсказать их переводы, обрезать по `</s>` и сложить правильные варианты и предсказанные в `refs` и `hyps` соответственно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YjYA3eohGlOA"
   },
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def evaluate_model(model, iterator):\n",
    "    model.eval()\n",
    "    refs, hyps = [], []\n",
    "    bos_index = iterator.dataset.fields['target'].vocab.stoi[BOS_TOKEN]\n",
    "    eos_index = iterator.dataset.fields['target'].vocab.stoi[EOS_TOKEN]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(iterator):\n",
    "            encoder_hidden = model.encoder(batch.source)\n",
    "\n",
    "            hidden = encoder_hidden\n",
    "            result = [LongTensor([bos_index]).expand(1, batch.target.shape[1])]\n",
    "\n",
    "            for _ in range(30):\n",
    "                step, hidden = model.decoder(result[-1], hidden)\n",
    "                step = step.argmax(-1)\n",
    "                result.append(step)\n",
    "\n",
    "            targets = batch.target.data.cpu().numpy().T\n",
    "            _, eos_indices = np.where(targets == eos_index)\n",
    "\n",
    "            targets = [target[:eos_ind] for eos_ind, target in zip(eos_indices, targets)]\n",
    "\n",
    "            refs.extend(targets)\n",
    "\n",
    "            result = torch.cat(result)\n",
    "            result = result.data.cpu().numpy().T\n",
    "            _, eos_indices = np.where(result == eos_index)\n",
    "            result = [res[:eos_ind] for eos_ind, res in zip(eos_indices, result)]\n",
    "            hyps.extend(result)\n",
    "            \n",
    "    return corpus_bleu([[ref] for ref in refs], hyps) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_E2JxfRuphch"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from tqdm import tqdm\n",
    "tqdm.get_lock().locks = []\n",
    "\n",
    "\n",
    "def do_epoch(model, criterion, data_iter, optimizer=None, name=None):\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    is_train = not optimizer is None\n",
    "    name = name or ''\n",
    "    model.train(is_train)\n",
    "    \n",
    "    batches_count = len(data_iter)\n",
    "    \n",
    "    with torch.autograd.set_grad_enabled(is_train):\n",
    "        with tqdm(total=batches_count) as progress_bar:\n",
    "            for i, batch in enumerate(data_iter):                \n",
    "                logits, _ = model(batch.source, batch.target)\n",
    "                \n",
    "                target = torch.cat((batch.target[1:], batch.target.new_ones((1, batch.target.shape[1]))))\n",
    "                loss = criterion(logits.view(-1, logits.shape[-1]), target.view(-1))\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "                if optimizer:\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    nn.utils.clip_grad_norm_(model.parameters(), 1.)\n",
    "                    optimizer.step()\n",
    "\n",
    "                progress_bar.update()\n",
    "                progress_bar.set_description('{:>5s} Loss = {:.5f}, PPX = {:.2f}'.format(name, loss.item(), \n",
    "                                                                                         math.exp(loss.item())))\n",
    "                \n",
    "            progress_bar.set_description('{:>5s} Loss = {:.5f}, PPX = {:.2f}'.format(\n",
    "                name, epoch_loss / batches_count, math.exp(epoch_loss / batches_count))\n",
    "            )\n",
    "            progress_bar.refresh()\n",
    "\n",
    "    return epoch_loss / batches_count\n",
    "\n",
    "\n",
    "def fit(model, criterion, optimizer, train_iter, epochs_count=1, val_iter=None):\n",
    "    best_val_loss = None\n",
    "    for epoch in range(epochs_count):\n",
    "        name_prefix = '[{} / {}] '.format(epoch + 1, epochs_count)\n",
    "        train_loss = do_epoch(model, criterion, train_iter, optimizer, name_prefix + 'Train:')\n",
    "        \n",
    "        if not val_iter is None:\n",
    "            val_loss = do_epoch(model, criterion, val_iter, None, name_prefix + '  Val:')\n",
    "            print('\\nVal BLEU = {:.2f}'.format(evaluate_model(model, val_iter)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5X2kYDU_rCjP"
   },
   "outputs": [],
   "source": [
    "model = TranslationModel(source_vocab_size=len(source_field.vocab), target_vocab_size=len(target_field.vocab), encoder_layers=2).to(DEVICE)\n",
    "\n",
    "pad_idx = target_field.vocab.stoi['<pad>']\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx).to(DEVICE)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "fit(model, criterion, optimizer, train_iter, epochs_count=30, val_iter=test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CHQpCQIPLSXd",
    "outputId": "27bf7044-6e12-4902-ca66-2ace50aefcb9"
   },
   "outputs": [],
   "source": [
    "evaluate_model(model, test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "MQUu5aDJvBDx",
    "outputId": "7c78eee3-d053-4db7-8b03-e065653810b9"
   },
   "outputs": [],
   "source": [
    "greedy_decode(model, \"Hello, world\", source_field, target_field)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xL8uOdOCs3nc"
   },
   "source": [
    "## Реализация attention'а\n",
    "\n",
    "В общем случае, attention работает так: пусть у нас есть набор скрытых состояний $\\mathbf{s}_1, \\ldots, \\mathbf{s}_m$ - представлений слов из исходного языка, полученных с помощью энкодера. И есть некоторое текущее скрытое состояние $\\mathbf{h}_i$ - скажем, представление, используемое для предсказания слова на нужном нам языке.\n",
    "\n",
    "Тогда с помощью аттеншена мы можем получить взвешенное представление контекста $\\mathbf{s}_1, \\ldots, \\mathbf{s}_m$ - вектор $\\mathbf{c}_i$:\n",
    "$$\n",
    "\\begin{align}\\begin{split}\n",
    "\\mathbf{c}_i &= \\sum\\limits_j a_{ij}\\mathbf{s}_j\\\\\n",
    "\\mathbf{a}_{ij} &= \\text{softmax}(f_{att}(\\mathbf{h}_i, \\mathbf{s}_j))\n",
    "\\end{split}\\end{align}\n",
    "$$\n",
    "\n",
    "$f_{att}$ - функция, которая говорит, насколько хорошо $\\mathbf{h}_i$ и $\\mathbf{s}_j$ подходят друг другу.\n",
    "\n",
    "Самые популярные её варианты:\n",
    "- Additive attention:\n",
    "$$f_{att}(\\mathbf{h}_i, \\mathbf{s}_j) = \\mathbf{v}_a{}^\\top \\text{tanh}(\\mathbf{W}_a\\mathbf{h}_i + \\mathbf{W}_b\\mathbf{s}_j)$$\n",
    "- Dot attention:\n",
    "$$f_{att}(\\mathbf{h}_i, \\mathbf{s}_j) = \\mathbf{h}_i^\\top \\mathbf{s}_j$$\n",
    "- Multiplicative attention:\n",
    "$$f_{att}(\\mathbf{h}_i, \\mathbf{s}_j) = \\mathbf{h}_i^\\top \\mathbf{W}_a \\mathbf{s}_j$$\n",
    "\n",
    "**Задание** Реализуйте Additive attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nNUltDmHtPl0"
   },
   "outputs": [],
   "source": [
    "class AdditiveAttention(nn.Module):\n",
    "    def __init__(self, query_size, key_size, hidden_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        # query - decoder state, (1, batch, rnn_hidden_dim)\n",
    "        # value - all encoder states, (seq_len, batch, rnn_hidden_dim)\n",
    "        # key_proj - self.key_layer(value), (seq_len, batch, hidden_dim)\n",
    "        # hidden_dim - size of attention layer\n",
    "        \n",
    "        self._query_layer = nn.Linear(query_size, hidden_dim)\n",
    "        self._key_layer = nn.Linear(key_size, hidden_dim)\n",
    "        self._energy_layer = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "    def forward(self, query, key_proj, value, mask=None):\n",
    "        # ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tWiXuWHltVpU"
   },
   "source": [
    "Обновим декодер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4D9A3aoO2k6Y"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim=128, rnn_hidden_dim=256, num_layers=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self._bidir = False\n",
    "        self._num_layers = num_layers\n",
    "        self._hidden_dim = rnn_hidden_dim // 2 if self._bidir else rnn_hidden_dim\n",
    "        \n",
    "        self._emb = nn.Embedding(vocab_size, emb_dim)\n",
    "        self._rnn = nn.GRU(input_size=emb_dim, hidden_size=self._hidden_dim, \n",
    "                           num_layers=num_layers, bidirectional=self._bidir, dropout=0.2)\n",
    "\n",
    "    def forward(self, inputs, hidden=None):\n",
    "        embs = self._emb(inputs)\n",
    "        # seq_len, batch_size, 1\n",
    "        outputs, h = self._rnn(embs, hidden) # у GRU нет h_c, а output нам не нужен\n",
    "        return outputs, h[-1].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NaAX28iQtVAs"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim=64, rnn_hidden_dim=256, attn_dim=128, num_layers=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self._emb = nn.Embedding(vocab_size, emb_dim)\n",
    "        self._rnn = nn.GRU(input_size=emb_dim + rnn_hidden_dim, \n",
    "                           hidden_size=rnn_hidden_dim, num_layers=num_layers)\n",
    "        self._out = nn.Linear(rnn_hidden_dim, vocab_size) \n",
    "        self._att = AdditiveAttention(rnn_hidden_dim, rnn_hidden_dim, attn_dim)\n",
    "        self._drop = nn.Dropout(p=0.3)\n",
    "\n",
    "    def forward(self, inputs, encoder_output, encoder_mask, hidden=None):\n",
    "        embs = self._emb(inputs)\n",
    "        outputs = []\n",
    "        attentions = []\n",
    "        key_proj = self._att._key_layer(encoder_output) # можно попробовать вынести в attention\n",
    "        for i in range(embs.shape[0]):\n",
    "            context, f_att = self._att(query=hidden, key_proj=key_proj,\n",
    "                                       value=encoder_output, mask=encoder_mask)\n",
    "            context = context.unsqueeze(0)\n",
    "            rnn_input = torch.cat((embs[i:i + 1], context), -1)\n",
    "            output, hidden = self._rnn(rnn_input, hidden)\n",
    "\n",
    "            outputs.append(output)\n",
    "            attentions.append(f_att)\n",
    "\n",
    "        output = self._drop(torch.cat(outputs))\n",
    "        attentions = torch.cat(attentions)\n",
    "        return self._out(output), hidden, attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S9L_aBVDs39U"
   },
   "outputs": [],
   "source": [
    "class TranslationModel(nn.Module):\n",
    "    def __init__(self, source_vocab_size, target_vocab_size, emb_dim=64, rnn_hidden_dim=128, \n",
    "                 attn_dim=128, encoder_num_layers=2):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = Encoder(source_vocab_size, emb_dim, rnn_hidden_dim, encoder_num_layers)\n",
    "        self.decoder = Decoder(target_vocab_size, emb_dim, rnn_hidden_dim, attn_dim, 1)\n",
    "        \n",
    "    def forward(self, source_inputs, target_inputs):\n",
    "        encoder_mask = source_inputs == 1\n",
    "        encoder_output, encoder_hidden = self.encoder(source_inputs)\n",
    "        return self.decoder(target_inputs, encoder_output, encoder_mask, encoder_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bZmMUAMktB3s"
   },
   "outputs": [],
   "source": [
    "model = TranslationModel(source_vocab_size=len(source_field.vocab), target_vocab_size=len(target_field.vocab)).to(DEVICE)\n",
    "\n",
    "model(batch.source, batch.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yQH0KwBsth1A"
   },
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def evaluate_model(model, iterator):\n",
    "    model.eval()\n",
    "    refs, hyps = [], []\n",
    "    bos_index = iterator.dataset.fields['target'].vocab.stoi[BOS_TOKEN]\n",
    "    eos_index = iterator.dataset.fields['target'].vocab.stoi[EOS_TOKEN]\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(iterator):\n",
    "            encoder_output, encoder_hidden = model.encoder(batch.source)\n",
    "            mask = batch.source == 1.\n",
    "            \n",
    "            hidden = encoder_hidden\n",
    "            result = [LongTensor([bos_index]).expand(1, batch.target.shape[1])]\n",
    "            \n",
    "            for _ in range(30):\n",
    "                step, hidden, _ = model.decoder(result[-1], encoder_output, mask, hidden)\n",
    "                step = step.argmax(-1)\n",
    "                result.append(step)\n",
    "            \n",
    "            targets = batch.target.data.cpu().numpy().T\n",
    "            eos_indices = (targets == eos_index).argmax(-1)\n",
    "            eos_indices[eos_indices == 0] = targets.shape[1]\n",
    "\n",
    "            targets = [target[:eos_ind] for eos_ind, target in zip(eos_indices, targets)]\n",
    "            refs.extend(targets)\n",
    "            \n",
    "            result = torch.cat(result)\n",
    "            result = result.data.cpu().numpy().T\n",
    "            eos_indices = (result == eos_index).argmax(-1)\n",
    "            eos_indices[eos_indices == 0] = result.shape[1]\n",
    "\n",
    "            result = [res[:eos_ind] for eos_ind, res in zip(eos_indices, result)]\n",
    "            hyps.extend(result)\n",
    "            \n",
    "    return corpus_bleu([[ref] for ref in refs], hyps) * 100\n",
    "\n",
    "\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "tqdm.get_lock().locks = []\n",
    "\n",
    "\n",
    "def do_epoch(model, criterion, data_iter, optimizer=None, name=None):\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    is_train = not optimizer is None\n",
    "    name = name or ''\n",
    "    model.train(is_train)\n",
    "    \n",
    "    batches_count = len(data_iter)\n",
    "    \n",
    "    with torch.autograd.set_grad_enabled(is_train):\n",
    "        with tqdm(total=batches_count) as progress_bar:\n",
    "            for i, batch in enumerate(data_iter):                \n",
    "                logits, _, _ = model(batch.source, batch.target)\n",
    "                \n",
    "                target = torch.cat((batch.target[1:], batch.target.new_ones((1, batch.target.shape[1]))))\n",
    "                loss = criterion(logits.view(-1, logits.shape[-1]), target.view(-1))\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "                if optimizer:\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    nn.utils.clip_grad_norm_(model.parameters(), 1.)\n",
    "                    optimizer.step()\n",
    "\n",
    "                progress_bar.update()\n",
    "                progress_bar.set_description('{:>5s} Loss = {:.5f}, PPX = {:.2f}'.format(name, loss.item(), \n",
    "                                                                                         math.exp(loss.item())))\n",
    "                \n",
    "            progress_bar.set_description('{:>5s} Loss = {:.5f}, PPX = {:.2f}'.format(\n",
    "                name, epoch_loss / batches_count, math.exp(epoch_loss / batches_count))\n",
    "            )\n",
    "            progress_bar.refresh()\n",
    "\n",
    "    return epoch_loss / batches_count\n",
    "\n",
    "\n",
    "def fit(model, criterion, optimizer, train_iter, epochs_count=1, val_iter=None):\n",
    "    best_val_loss = None\n",
    "    for epoch in range(epochs_count):\n",
    "        name_prefix = '[{} / {}] '.format(epoch + 1, epochs_count)\n",
    "        train_loss = do_epoch(model, criterion, train_iter, optimizer, name_prefix + 'Train:')\n",
    "        \n",
    "        if not val_iter is None:\n",
    "            val_loss = do_epoch(model, criterion, val_iter, None, name_prefix + '  Val:')\n",
    "            print('\\nVal BLEU = {:.2f}'.format(evaluate_model(model, val_iter)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2xCA3DhBtvYM"
   },
   "outputs": [],
   "source": [
    "model = TranslationModel(source_vocab_size=len(source_field.vocab), target_vocab_size=len(target_field.vocab)).to(DEVICE)\n",
    "\n",
    "pad_idx = target_field.vocab.stoi['<pad>']\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx).to(DEVICE)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "fit(model, criterion, optimizer, train_iter, epochs_count=30, val_iter=test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kXOkzWyIuDRo"
   },
   "outputs": [],
   "source": [
    "def greedy_decode(model, source_text, source_field, target_field):\n",
    "    bos_index = target_field.vocab.stoi[BOS_TOKEN]\n",
    "    eos_index = target_field.vocab.stoi[EOS_TOKEN]\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        result, attentions = [], []\n",
    "        source = source_field.preprocess(source_text)\n",
    "        inputs = source_field.process([source]).to(DEVICE)\n",
    "        \n",
    "        encoder_output, encoder_hidden = model.encoder(inputs)\n",
    "        encoder_mask = torch.zeros_like(inputs).byte()\n",
    "        \n",
    "        hidden = encoder_hidden\n",
    "        step = LongTensor([[bos_index]])\n",
    "        \n",
    "        for _ in range(50):\n",
    "            step, hidden, attention = model.decoder(step, encoder_output, encoder_mask, hidden)\n",
    "            step = step.argmax(-1)\n",
    "            attentions.append(attention.squeeze(1))\n",
    "          \n",
    "            if step.squeeze().item() == eos_index:\n",
    "                break\n",
    "            \n",
    "            result.append(step.item())   \n",
    "        result = [target_field.vocab.itos[ind] for ind in result]\n",
    "        return source, result, torch.cat(attentions, -1).data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0dacXWf3uETQ"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_heatmap(src, trg, scores):\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    heatmap = ax.pcolor(scores, cmap='viridis')\n",
    "\n",
    "    ax.set_xticklabels(trg, minor=False, rotation=45)\n",
    "    ax.set_yticklabels(src, minor=False)\n",
    "\n",
    "    ax.xaxis.tick_top()\n",
    "    ax.set_xticks(np.arange(scores.shape[1]) + 0.5, minor=False)\n",
    "    ax.set_yticks(np.arange(scores.shape[0]) + 0.5, minor=False)\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    plt.colorbar(heatmap)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CAnRu2cMuFno"
   },
   "outputs": [],
   "source": [
    "source, result, attentions = greedy_decode(model, \"I didn't pay.\", source_field, target_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "id": "5cJcUv_suGns",
    "outputId": "acf7e2f8-a358-490f-ee4c-2db128ff1b2a"
   },
   "outputs": [],
   "source": [
    "plot_heatmap(source + ['</s>'], result + ['</s>'], attentions)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
