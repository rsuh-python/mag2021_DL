{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iF98z0fxWwnL"
   },
   "source": [
    "При подготовке использовались [материалы](https://github.com/mannefedov/compling_nlp_hse_course/blob/master/2020/nn_intro_torch.ipynb) курса Михаила Нефедова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CgiT9Xow1sd5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FfxNXovr1sd6"
   },
   "source": [
    "### Классификация твитов по тональности\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sZtLedfF00Ih"
   },
   "source": [
    "#### Скачивание и подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VEBb-YaTR1os",
    "outputId": "b3f61134-ef4f-4fe0-e1a1-a06baab263be"
   },
   "outputs": [],
   "source": [
    "!wget -O positive.csv https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv?dl=0\n",
    "!wget -O negative.csv https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv?dl=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q6WWZiab6rTw"
   },
   "outputs": [],
   "source": [
    "pos_tweets = pd.read_csv('positive.csv', encoding='utf-8', sep=';', header=None,  names=[0,1,2,'text','tone',5,6,7,8,9,10,11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sq86SbhB69yc"
   },
   "outputs": [],
   "source": [
    "neg_tweets = pd.read_csv('negative.csv', encoding='utf-8', sep=';', header=None, names=[0,1,2,'text','tone',5,6,7,8,9,10,11] )\n",
    "neg_tweets['tone'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nCIj1hmt1sd8",
    "outputId": "769b190e-79dd-4ce8-9255-e52f5c9b1e13"
   },
   "outputs": [],
   "source": [
    "all_tweets_data = pos_tweets.append(neg_tweets)\n",
    "print(len(all_tweets_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7J8hlg46D73C"
   },
   "outputs": [],
   "source": [
    "tweets_data = shuffle(all_tweets_data[['text','tone']])[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_JYJtXCaERbb"
   },
   "outputs": [],
   "source": [
    "train_sentences, val_sentences = train_test_split(tweets_data, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362
    },
    "id": "j0akXE9bPSGs",
    "outputId": "9701488b-e4aa-4446-d9a7-ade2e9641817"
   },
   "outputs": [],
   "source": [
    "train_sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a8DdyDMU1sd-"
   },
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    tokens = text.lower().split()\n",
    "    tokens = [token.strip(punctuation) for token in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h-q1JHzW1sd-"
   },
   "source": [
    "Теперь нам нужно собрать все уникальные слова в словарь. Лучше сразу посчитать количество упоминаний, чтобы отсеять самые редкие."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T8t4nDCR1sd-",
    "outputId": "7784301f-2abd-4c43-9ae3-ac8295154805"
   },
   "outputs": [],
   "source": [
    "vocab = Counter()\n",
    "\n",
    "for text in tweets_data['text']:\n",
    "    vocab.update(preprocess(text))\n",
    "print('всего уникальных токенов:', len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0wKHM_LU1seA",
    "outputId": "8c2a2ea8-3473-4efd-9dbf-bc704ca28ed6"
   },
   "outputs": [],
   "source": [
    "filtered_vocab = set()\n",
    "\n",
    "for word in vocab:\n",
    "    if vocab[word] > 2:\n",
    "        filtered_vocab.add(word)\n",
    "print('уникальных токенов, втретившихся больше 2 раз:', len(filtered_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BEUhJv5N1seC"
   },
   "outputs": [],
   "source": [
    "#создаем словарь с индексами word2id, для спецсимвола паддинга дефолтный индекс - 0\n",
    "word2id = {'PAD':0}\n",
    "\n",
    "for word in filtered_vocab:\n",
    "    word2id[word] = len(word2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P6J89I9d1seC"
   },
   "outputs": [],
   "source": [
    "#обратный словарь для того, чтобы раскодировать последовательность\n",
    "id2word = {i:word for word, i in word2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YrzM7MnCQeP_",
    "outputId": "fdd46d22-8f06-48eb-cddf-bec4393de4b4"
   },
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wwYqFI2V1seC"
   },
   "source": [
    "#### паддинги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZyQRVkaU1seD",
    "outputId": "98ce3fd8-913a-47c7-d6db-b5f54d68f2b3"
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 0\n",
    "\n",
    "for text in tweets_data.text:\n",
    "    tokens = preprocess(text)\n",
    "    MAX_LEN = max(len(tokens), MAX_LEN)\n",
    "MAX_LEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F-I5GJSh1seF"
   },
   "source": [
    "##### F.pad \n",
    "паддим каждую последовательность до желаемой длины"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XVpo8mLL1seF"
   },
   "outputs": [],
   "source": [
    "\n",
    "X = torch.LongTensor(size=(train_sentences.shape[0], MAX_LEN))\n",
    "\n",
    "for i, text in enumerate(train_sentences.text):\n",
    "    tokens = preprocess(text) # токенизируем\n",
    "    \n",
    "    ids = [word2id[token] for token in tokens if token in word2id][:MAX_LEN]\n",
    "\n",
    "    ids = F.pad(torch.LongTensor(ids), (0,MAX_LEN-len(ids)))\n",
    "    X[i] = ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8yLHfFi81seF",
    "outputId": "5647214a-871f-4a66-c734-c69cb53e8311"
   },
   "outputs": [],
   "source": [
    "print(X[4].shape)\n",
    "print(X[4])\n",
    "print([id2word[int(id_)] for id_ in  X[4]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PXTjauwg1seG"
   },
   "source": [
    "##### torch.nn.utils.rnn.pad_sequence\n",
    "альтернатива - добиваем паддингами до самого длинного предложения из переданных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GlQ-yu7w1seG"
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "\n",
    "for text in train_sentences.text:\n",
    "    tokens = preprocess(text) \n",
    "    ids = torch.LongTensor([word2id[token] for token in tokens if token in word2id]) \n",
    "    X.append(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pU3KmLJ21seG",
    "outputId": "0da55269-1887-4998-cb5b-9f2f3bb15ffc"
   },
   "outputs": [],
   "source": [
    "X = pad_sequence(X, batch_first=True) \n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pbeogUEq1seH"
   },
   "outputs": [],
   "source": [
    "X = X[:, :5] # если хочется обрезать короче"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LLIbatumj8ts",
    "outputId": "990524ed-536c-4dd6-ff3f-e766b82718c5"
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "obiXRWLt1OZJ"
   },
   "source": [
    "#### Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FMs4ZohJ1seI"
   },
   "outputs": [],
   "source": [
    "class TweetsDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataset, word2id, DEVICE):\n",
    "        self.dataset = dataset['text'].values\n",
    "        self.word2id = word2id\n",
    "        self.length = dataset.shape[0]\n",
    "        self.target = dataset['tone'].values\n",
    "        self.device = DEVICE\n",
    "\n",
    "    def __len__(self): #это обязательный метод, он должен уметь считать длину датасета\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index): #еще один обязательный метод. По индексу возвращает элемент выборки\n",
    "        tokens = self.preprocess(self.dataset[index]) # токенизируем\n",
    "        ids = torch.LongTensor([self.word2id[token] for token in tokens if token in self.word2id])\n",
    "        y = [self.target[index]]\n",
    "        return ids, y\n",
    "    \n",
    "    def preprocess(self, text):\n",
    "        tokens = text.lower().split()\n",
    "        tokens = [token.strip(punctuation) for token in tokens]\n",
    "        tokens = [token for token in tokens if token]\n",
    "        return tokens\n",
    "\n",
    "    def collate_fn(self, batch): #этот метод можно реализовывать и отдельно,\n",
    "    # он понадобится для DataLoader во время итерации по батчам\n",
    "      ids, y = list(zip(*batch))\n",
    "      padded_ids = pad_sequence(ids, batch_first=True).to(self.device)\n",
    "      #мы хотим применять BCELoss, он будет брать на вход predicted размера batch_size x 1 (так как для каждого семпла модель будет отдавать одно число), target размера batch_size x 1\n",
    "      y = torch.Tensor(y).to(self.device) # tuple ([1], [0], [1])  -> Tensor [[1.], [0.], [1.]] \n",
    "      return padded_ids, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m5Wjfyxar7U1"
   },
   "source": [
    "##### создаем итераторы по данным для трейна и теста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Zl4FxB71seI"
   },
   "outputs": [],
   "source": [
    "train_dataset = TweetsDataset(train_sentences, word2id, DEVICE)\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "train_iterator = DataLoader(train_dataset, collate_fn = train_dataset.collate_fn, sampler=train_sampler, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N9cB8gEijwRU",
    "outputId": "9957cbd1-7f96-4435-a494-d872d4552c26"
   },
   "outputs": [],
   "source": [
    "len(train_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xauLXZwQNcCq"
   },
   "outputs": [],
   "source": [
    "batch = next(iter(train_iterator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aZbD27_A6Nck",
    "outputId": "2eb85346-44ea-413d-91ce-a57ccea87a9c"
   },
   "outputs": [],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZR_upb-_1seJ"
   },
   "outputs": [],
   "source": [
    "val_dataset = TweetsDataset(val_sentences, word2id, DEVICE)\n",
    "val_sampler = SequentialSampler(val_dataset)\n",
    "val_iterator = DataLoader(val_dataset, collate_fn = val_dataset.collate_fn, sampler=val_sampler, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jQlpcUR28V-j"
   },
   "outputs": [],
   "source": [
    "test_batch = next(iter(val_iterator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xN5tyh7ggvIO"
   },
   "source": [
    "#### Embedding  слой\n",
    "перед тем как собрать сеть целиком посмотрим на слои, которые пока не обсуждались\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gUkLVZPVf6uA"
   },
   "outputs": [],
   "source": [
    "layer = nn.Embedding(10, 5) # первый параметр  - размер всего словаря, второй параметр размер получаемого эмбеддинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oCEoKFd4gdBP",
    "outputId": "b2ab3c41-fcb6-4414-d7cc-d3483eedd83a"
   },
   "outputs": [],
   "source": [
    "layer.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "spQ6QW-pk0JR",
    "outputId": "175ef898-f8b1-45a5-d54c-a70292604794"
   },
   "outputs": [],
   "source": [
    "input = torch.tensor([1, 4, 3, 3, 7, 0, 9])\n",
    "result = layer(input)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cmDPByEWoq0n"
   },
   "source": [
    "#### Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4g016LuzkcvY"
   },
   "outputs": [],
   "source": [
    "dropout = nn.Dropout(p=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5UMarRwiKtq1",
    "outputId": "1f57d46f-f224-4cfe-d1e7-3c4fa46ff16e"
   },
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SaBowijfkoHy",
    "outputId": "9a8de483-66d2-4796-87a7-5342c6813bf5"
   },
   "outputs": [],
   "source": [
    "dropout(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BUCT8ayD1seK"
   },
   "source": [
    "#### MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NdV7oSIc1seK"
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        \n",
    "        super().__init__()          \n",
    "        # указываем в атрибутах класса, какие слои и активации нам понадобятся\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.emb2h = nn.Linear(embedding_dim, 10) \n",
    "        self.act1 = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.h2out = nn.Linear(10, 1)\n",
    "        self.act2 = nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "    def forward(self, text): #необходимый метод,  в нем указываем, как именно связываются слои/активации между собой\n",
    "        # batch_size x seq_len\n",
    "        #ipdb.set_trace()\n",
    "        embedded = self.embedding(text)   # переводим последовательность индексов в последовательность эмбеддингов\n",
    "        # batch_size x seq_len x embedding_dim\n",
    "        \n",
    "        mean_emb = torch.mean(embedded, dim=1) # считаем средний эмбеддинг предложения\n",
    "        # batch_size x embedding_dim\n",
    "        hidden = self.emb2h(mean_emb) # пропускаем эмбеддинг через полносвязный слой \n",
    "        # batch_size x 10\n",
    "        hidden = self.act1(hidden)\n",
    "        # batch_size x 10\n",
    "        hidden = self.dropout(hidden)\n",
    "        # batch_size x 10\n",
    "        out = self.h2out(hidden) # возвращаем одно число для каждого семпла\n",
    "        # batch_size x 1\n",
    "        proba = self.act2(out) # пропускаем число через сигмоиду, делая из него вероятность класса\n",
    "        # batch_size x 1\n",
    "        return proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YFQ-WEY4cxkv",
    "outputId": "e2db59e9-fcf6-4344-f653-3cbee0ccad5e"
   },
   "outputs": [],
   "source": [
    "batch, y = next(iter(train_iterator))\n",
    "batch, y = batch.to(device='cpu'), y.to(device='cpu')\n",
    "print(batch.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JSmsX_fg4LcO",
    "outputId": "a024699c-c010-4c08-a02a-51c753863bcf"
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oHc9E_96dJBH",
    "outputId": "f55a5850-b7ad-480d-98d4-19c4cada56d7"
   },
   "outputs": [],
   "source": [
    "#пропустим через модель наш первый батч, чтобы проверить, что все работает\n",
    "model = MLP(len(id2word), 5)\n",
    "output = model(batch)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CBWdfROdQK5v",
    "outputId": "ab406c85-da55-4719-f6cb-f0dee5148e09"
   },
   "outputs": [],
   "source": [
    "loss = nn.BCELoss()\n",
    "loss(output, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PFsH8SWU5E9Z",
    "outputId": "7b49fb6d-33c4-4c21-cf54-3f7a5c9533ed"
   },
   "outputs": [],
   "source": [
    "model.state_dict() # где посмотреть веса модели (ее параметры)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cYz0OzYT1vt1"
   },
   "source": [
    "#### training loop, логика обучения и валидации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K8sZOK7Kvk7o"
   },
   "source": [
    "теперь нам нужны функции для обучения и валидации,\n",
    "каждый вызов функции - одна эпоха обучения \n",
    "\n",
    "За одну эпоху нам надо для каждого батча:\n",
    "\n",
    "-- применить к нему модель, \n",
    "\n",
    "-- посчитать значение функции потерь, \n",
    "\n",
    "-- посчитать градиенты,\n",
    "\n",
    "-- обновить веса (параметры модели)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BVKQzPPI1seJ"
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    print('Training...')\n",
    "    epoch_loss = 0 # для подсчета среднего лосса на всех батчах\n",
    "    model.train()  # ставим модель в обучение, явно указываем, что сейчас надо будет хранить градиенты у всех весов\n",
    "\n",
    "    for i, (texts, ys) in enumerate(iterator): #итерируемся по батчам\n",
    "        optimizer.zero_grad()  #обнуляем градиенты\n",
    "        #ipdb.set_trace()\n",
    "        preds_proba = model(texts) #прогоняем данные через модель\n",
    "        loss = criterion(preds_proba, ys) #считаем значение функции потерь  \n",
    "        loss.backward() #считаем градиенты  \n",
    "        optimizer.step() #обновляем веса \n",
    "        epoch_loss += loss.item() #сохраняем значение функции потерь\n",
    "        \n",
    "        if not (i + 1) % 20:\n",
    "            print(f'Train loss: {epoch_loss/i}')\n",
    "        \n",
    "    return epoch_loss / len(iterator) # возвращаем среднее значение функции потерь по всей выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EPfO7p9x1seK"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    print(\"\\nValidating...\")\n",
    "    epoch_loss = 0\n",
    "    model.eval() \n",
    "    with torch.no_grad():\n",
    "        for i, (texts, ys) in enumerate(iterator):   \n",
    "            predictions = model(texts)  # делаем предсказания на тесте\n",
    "            loss = criterion(predictions, ys)   # считаем значения функции ошибки для статистики  \n",
    "            epoch_loss += loss.item() \n",
    "            if not (i + 1) % 5:\n",
    "              print(f'Val loss: {epoch_loss/i}')\n",
    "        \n",
    "    return epoch_loss / len(iterator) # возвращаем средний лосс по батчам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VRoSupMNQsvF"
   },
   "source": [
    "#### инициализируем модель, задаем оптимизатор и функцию потерь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WO35IZES1seL"
   },
   "outputs": [],
   "source": [
    "model = MLP(len(word2id), 5)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.BCELoss() # Binary Cross Entropy\n",
    "\n",
    "# веса модели и значения лосса храним там же, где и все остальные тензоры\n",
    "model = model.to(DEVICE)\n",
    "criterion = criterion.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3kHbVX0y1seL"
   },
   "source": [
    "#### запуск обучения!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "boMAjlVM1seM",
    "outputId": "e9d98c33-e928-4207-d499-67d1c1dea227"
   },
   "outputs": [],
   "source": [
    "losses = []\n",
    "losses_eval = []\n",
    "\n",
    "for i in range(20):\n",
    "    print(f'\\nstarting Epoch {i}')\n",
    "    epoch_loss = train(model, train_iterator, optimizer, criterion)\n",
    "    losses.append(epoch_loss)\n",
    "\n",
    "    epoch_loss_on_test = evaluate(model, val_iterator, criterion)\n",
    "    losses_eval.append(epoch_loss_on_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "CAiTYQpe1seM",
    "outputId": "aa0982f3-c231-47b9-b8fd-d0ade19ab26d"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(losses)\n",
    "plt.plot(losses_eval)\n",
    "plt.title('BCE loss value')\n",
    "plt.ylabel('BCE loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G_lLwf57g7BC"
   },
   "source": [
    "# как инициализировать модель готовыми эмбеддингами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s8clxCNuhFIp"
   },
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mluNWIODDgsj"
   },
   "outputs": [],
   "source": [
    "texts = all_tweets_data.text.apply(preprocess).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y0WgMc-ZrcMo",
    "outputId": "3bdb98f1-9569-420c-ac86-fad919741f87"
   },
   "outputs": [],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8KPT0V82jGH5",
    "outputId": "eee55f2c-d832-421d-8bf5-af1c6f8bd71f"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "w2v = gensim.models.Word2Vec(texts, size=100, window=5, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0fhjhwxCjJC1",
    "outputId": "24033297-113c-45c8-b3b4-f80e9ea76f74"
   },
   "outputs": [],
   "source": [
    "w2v.wv.most_similar('веселый')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gHi83qVHqa-m"
   },
   "outputs": [],
   "source": [
    "weights = np.zeros((len(word2id), 100))\n",
    "count = 0\n",
    "for word, i in word2id.items():\n",
    "    if word == 'PAD':\n",
    "        continue   \n",
    "    try:\n",
    "        weights[i] = w2v.wv[word]    \n",
    "    except KeyError:\n",
    "      count += 1\n",
    "      # oov словам сопоставляем случайный вектор\n",
    "      weights[i] = np.random.normal(0,0.1,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NHsq7Lpux5aR"
   },
   "outputs": [],
   "source": [
    "class MLP_w2v(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size):\n",
    "        \n",
    "        super().__init__()          \n",
    "        # указываем в атрибутах класса, какие слои и активации нам понадобятся\n",
    "        self.embedding = nn.Embedding(vocab_size, 100)\n",
    "        self.embedding.from_pretrained(torch.tensor(weights), freeze=True)\n",
    "        self.emb2h = nn.Linear(100, 10) \n",
    "        self.act1 = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.h2out = nn.Linear(10, 1)\n",
    "        self.act2 = nn.Sigmoid() \n",
    "        \n",
    "        \n",
    "    def forward(self, text): #необходимый метод,  в нем указываем, как именно связываются слои/активации между собой\n",
    "        \n",
    "        embedded = self.embedding(text)   # переводим последовательность индексов в последовательность эмбеддингов\n",
    "        mean_emb = torch.mean(embedded, dim=1) # считаем средний эмбеддинг предложения\n",
    "        hidden = self.emb2h(mean_emb) # пропускаем эмбеддинг через полносвязный слой \n",
    "        hidden = self.dropout(hidden)\n",
    "        hidden = self.act1(hidden)\n",
    "        hidden = self.dropout(hidden)\n",
    "        out = self.h2out(hidden) # возвращаем одно число для каждого семла\n",
    "        proba = self.act2(out) # пропускаем число через сигмоиду, делая из него вероятность класса\n",
    "        \n",
    "        return proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IeBN7WHryzdk"
   },
   "outputs": [],
   "source": [
    "model = MLP_w2v(len(word2id))\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.BCELoss() # Binary Cross Entropy\n",
    "\n",
    "# веса модели и значения лосса храним там же, где и все остальные тензоры\n",
    "model = model.to(DEVICE)\n",
    "criterion = criterion.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t07vQjj0y8HM",
    "outputId": "6bedd3cf-7f4c-43d1-a3f7-d4637f949e85"
   },
   "outputs": [],
   "source": [
    "losses = []\n",
    "losses_eval = []\n",
    "\n",
    "for i in range(12):\n",
    "    print(f'\\nstarting Epoch {i}')\n",
    "    epoch_loss = train(model, train_iterator, optimizer, criterion)\n",
    "    losses.append(epoch_loss)\n",
    "\n",
    "    epoch_loss_on_test = evaluate(model, val_iterator, criterion)\n",
    "    losses_eval.append(epoch_loss_on_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "UHhM8MiEzVtl",
    "outputId": "f6af6960-8ef1-4d9f-9ab3-74e39f8e1d81"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(losses)\n",
    "plt.plot(losses_eval)\n",
    "plt.title('BCE loss value')\n",
    "plt.ylabel('BCE loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "CTOkNNrdrsA9"
   ],
   "name": "mlp_torch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
