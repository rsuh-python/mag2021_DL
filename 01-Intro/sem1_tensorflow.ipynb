{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B8ymkN6ME6k-"
   },
   "source": [
    "# Простейшие нейронные сети с Keras\n",
    "\n",
    "\n",
    "Фреймворк Keras+Tensorflow сейчас стремительно теряет популярность, но еще совсем недавно многие сетки писались именно на нем, поэтому какое-то базовое знакомство все равно пригодится. Сейчас актуальна версия TF номер 2.\n",
    "\n",
    "Одна из особенностей новой версии заключается в том, что Keras (раньше он был посторонней библиотекой-надстройкой) фактически [стал частью tensorflow.](https://www.tensorflow.org/guide/keras?hl=ru)  \n",
    "\n",
    "Изначально Keras создавался как высокоуровневое API для theano (это когда написали кучу функций один раз, красиво их назвали и завернули в пакет). Потом он начал поддерживать tensorflow, а сейчас вот чуть ли ни аннексия произошла. __Keras наш.__ Именно со знакомства с ним мы и начнём наше погружение в нейросетки.  \n",
    "\n",
    "Чтобы установить библиотеку, отправляйтесь в консоль и пропишите \n",
    "\n",
    "```\n",
    "pip install tensorflow\n",
    "```\n",
    "\n",
    "Если вы до этого сидели на старой версии tensorflow, на всякий случай снесите её. Иначе при установке могут возникнуть какие-нибудь несовместимости и ошибки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eq1ZAEkyE6lB"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xO5nW2iSE6lB",
    "outputId": "45b74698-40c7-47aa-c0be-c81a0041cbaf"
   },
   "outputs": [],
   "source": [
    "# Подгружаем tensorflow \n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tAKxh_oCE6lC"
   },
   "outputs": [],
   "source": [
    "# Подгрузим ещё немного пакетов :) \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UIpmSDYzE6lC"
   },
   "source": [
    "## 1. О данных и бейзлайнах\n",
    "\n",
    "Наша главная цель - как следует потрогать Keras своими руками. Мы хотим увидеть, что он реально позволяет обращаться с нейронками как с конструктором LEGO и предлагает нам для сборки башен кучу деталей. \n",
    "\n",
    "__Делать всё это мы будем на животных.__ Ежегодно около 7.6 миллионов бедных животных в США оказываются в приютах. Часть из них находит себе новую семью, часть возвращается к старому (бывает, что питомец потерялся и его нашли на улице), а часть погибает. Ужегодно усыпляется около 2.7 млн. собак и кошек.  \n",
    "\n",
    "Используя датасет с входной информацией (цвет, пол, возраст и т.п.) из одного из приютов, мы попытаемся спрогнозировать что произойдёт с новыми животными, которые попадут в этот приют. Данные, используемые в тетрадке уже были предварительно обработаны и приведены в удобную для построения моделей форму. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "vmnjPwzwE6lC",
    "outputId": "5fc03c5e-5f48-4a77-854f-5010ec46c50a"
   },
   "outputs": [],
   "source": [
    "X = pd.read_csv('data/X_cat.csv', sep = '\\t', index_col=0)\n",
    "target = pd.read_csv('data/y_cat.csv', sep = '\\t', index_col=0, names=['status'])\n",
    "\n",
    "print(X.shape)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g4bhDhjGE6lD"
   },
   "source": [
    "В датасете находится около 27 тысяч наблюдений и 39 регрессоров. Посмотрим на то как выглядит распределение того, что произошло со зверятами по особям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5YzSG7ThE6lD",
    "outputId": "d5a4dcda-df98-4e76-de5b-82ee93a1ba12"
   },
   "outputs": [],
   "source": [
    "target.status.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "It4qfdGrE6lD"
   },
   "source": [
    "Видим, что классы несбалансированы. Попробуем оставить четыре класса и объединить класс умерших животных с классом животных, которых усыпили. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "edaI83l-E6lD"
   },
   "outputs": [],
   "source": [
    "target = target.values\n",
    "target[target == 'Died'] = 'Euthanasia'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fBCduzE8E6lE"
   },
   "source": [
    "Закодируем классы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KxQ1nXUXE6lE",
    "outputId": "d70d6027-8812-4693-dde7-b9b32db88196"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(target)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f2DzyUOdE6lE",
    "outputId": "b3dc4961-93a4-48dc-c856-cb48ea0e7611"
   },
   "outputs": [],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9LA3UOMFE6lE",
    "outputId": "98100a72-0f2a-4d9c-c8ca-9faaec4552ae"
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tWsqEt4wE6lE"
   },
   "source": [
    "Разобьём выборку на тренировочную и тестовую. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lrP45F7QE6lE",
    "outputId": "944b1ab7-3a72-4c46-ca72-bbffde7d6ca5"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify = y, random_state = 42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n9y4wiHiE6lF"
   },
   "source": [
    "Прежде, чем учить 228-слойных монстров, давайте построим какие-нибудь простые прогнозы, чтобы было с чем сравнить. Давайте построим наивный прогноз, а также обучим линейную регрессию и случайный лес.\n",
    "\n",
    "### Константный прогноз\n",
    "\n",
    "Построим константный прогноз, чтобы было с чем сравнивать и прогноз по какой-нибудь модели. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1N9iMsmXE6lF",
    "outputId": "de1ddbbf-1011-461d-925b-1cf757095f08"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "probas = np.array(pd.Series(y_train).value_counts(normalize=True).sort_index().tolist())\n",
    "probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "coXun40zE6lF",
    "outputId": "e5f63bd6-230d-4a7c-cef5-990895a06265"
   },
   "outputs": [],
   "source": [
    "log_loss(y_test, np.tile(probas, X_test.shape[0]).reshape(X_test.shape[0], 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HaTkw_q_E6lF"
   },
   "source": [
    "### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "41iSJL90E6lF",
    "outputId": "8a30f88c-5843-4b4e-d3aa-ac0e799bcd01"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# обучите логистическую регрессию с предсказанием вероятностей (predict_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jvarc3YQE6lF",
    "outputId": "795b4bda-e73c-47cc-8d26-30a7da11980f"
   },
   "outputs": [],
   "source": [
    "# выведите предсказания модели на тесте"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nObHDZEbE6lF"
   },
   "source": [
    "### Случайный лес "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8kno_KGnE6lF",
    "outputId": "719f47b1-6476-43a9-e901-102c77d7f307",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# обучите рандомный лес и посчитайте logloss "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OKDlg0ERE6lG"
   },
   "source": [
    "Попробуем улучшить результат с помощью нейросеток. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pbstxpA-E6lG"
   },
   "source": [
    "## 2. Собираем свою нейросеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NqmE93ktE6lG"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers as L         # Уже готовые слои для моделей\n",
    "from tensorflow.keras.models import Sequential   # Специальный класс для склеивания слоёв\n",
    "from tensorflow.keras.models import Model        # Альтернативный класс для склейки слоёв\n",
    "import tensorflow.keras.optimizers as opt        # Разные оптимизационные алгоритмы :3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2eHw6HH2E6lG"
   },
   "source": [
    "Модель в Keras собирается как конструктор LEGO. Её можно описать двумя основными способами. Первый — последовательное описание модели. В его случае мы как бы создаём коробочку `model` и постепенно добавляем туда детальки нашей сетки. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "P36IfnjGE6lG"
   },
   "source": [
    "model = Sequential()                             # создали контейнер для модели\n",
    "model.add(layers.Dense(128, input_shape=(20,)))  # слой из 128 нейронов, вход 20 регрессоров\n",
    "model.add(layers.Activation('relu'))             # функция активации\n",
    "model.add(layers.Dropout(0.5))                   # дропаут с вероятностью 0.5 \n",
    "model.add(layers.Dense(1))                       # полносвязный слой с одним нейроном, то есть выходом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X8pCKnHUE6lG"
   },
   "source": [
    "Второй способ - описать модель функционально, в явном виде прописав какие аргументы идут на вход какому слою. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "4OZ2aDTSE6lG"
   },
   "source": [
    "a = Input(shape=(20,))                # Первая заглушка для входа \n",
    "b = layers.Dense(128)(a)              # Применяем ко входу полносвязный слой как функцию\n",
    "b = layers.Activation('relu')(b)      # Теперь к тому, что получилось функцию активации\n",
    "b = layers.Dropout(0.5)(b)            # Ну и так далее... \n",
    "b = layers.Dense(1)(b)\n",
    "\n",
    "model = Model(inputs=a, outputs=b)    # указываем что вход, а что выход, склеивая модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZsTSc8jbE6lG"
   },
   "source": [
    "Когда мы будем строить сложные модели с кучей разветвлений, для нас будет удобным второй способ. Для простых ситуаций вроде текущей, можете пользоваться первым. \n",
    "\n",
    "Давайте соберём небольшую нейронку. Давайте сделаем в ней вот такую архитектуру: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AahKQdD2E6lG"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Accuracy\n",
    "\n",
    "def get_new_model():\n",
    "    acc = Accuracy()\n",
    "\n",
    "    ###########################################################\n",
    "    model = Sequential(name = 'Archibald')  # модели можно дать имя!\n",
    "    \n",
    "    # Добавляем в нашу модель первый слой из 25 нейронов\n",
    "    model.add(L.Dense(25, input_dim = X_train.shape[1], kernel_initializer='random_normal'))\n",
    "\n",
    "    # Добавляем функцию активации на первый слой \n",
    "    model.add(L.Activation('sigmoid'))\n",
    "\n",
    "    # Добавляем ещё один слой из 25 нейронов\n",
    "    model.add(L.Dense(25, kernel_initializer='random_normal'))\n",
    "    model.add(L.Activation('sigmoid'))\n",
    "\n",
    "    # На выходе мы должны получить вероятности того, что объект относится к разным классам \n",
    "    # Сделать такое преобразование позволяет softmax как функция активации\n",
    "    # На выход будет идти 4 вероятности по числу классов\n",
    "    model.add(L.Dense(4, activation='softmax', kernel_initializer = 'random_normal'))\n",
    "    \n",
    "    ###########################################################\n",
    "    \n",
    "    # В качестве оптимизации будем использовать Adam\n",
    "    # Это такой специальный градиентный спуск, обсудим его в следущий раз\n",
    "    optimizer = opt.Adam(lr=1e-3)\n",
    "\n",
    "    # Собираем модель\n",
    "    model.compile(loss = 'categorical_crossentropy', \n",
    "                  metrics=['acc'], \n",
    "                  optimizer=optimizer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RTY0pRBZE6lG"
   },
   "source": [
    "Перед тем как обучать нашу нейросеть, нужно задать параметры обучения. Во-первых, метод оптимизации. Во-вторых, функцию потерь. В-третьих, парочку метрик, на которые нам хотелось бы смотреть в процессе обучения.  Для этого есть метод `compile`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J0UCdmW_E6lH"
   },
   "outputs": [],
   "source": [
    "model = get_new_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jh4x87aeE6lH"
   },
   "source": [
    "Итак, только что мы собрали свою первую нейросеть со скрытым слоем.   Посмотрим сколько параметров нам предстоит оценить. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BJSNnENTE6lH",
    "outputId": "f67485a7-5dc3-445a-e264-e646135e5149"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M7u3zSafE6lH"
   },
   "source": [
    "Видим, что нужно оценить огромное количество параметров. На оценку каждого параметра придётся совсем маленькое количество наблюдений. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NlUSmmIBE6lH",
    "outputId": "29419f2c-7a72-4f5d-98ff-d1604f547a4a"
   },
   "outputs": [],
   "source": [
    "X_train.shape[0] / 1704"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2qvREpo9E6lH"
   },
   "source": [
    "Отлично! Модель собрана. Осталось её обучить. Метод `fit` позволяет сделать это. Он принимает на вход обучающую выборку `X_train, y_train`. Параметр  `batch_size` это  размер батча. Этот параметр ограничивает количество примеров, которое за раз подаётся в нашу нейронную сеть. Количиство эпох для обучения, `epochs` - это число проходов модели по обучающей выборке. \n",
    "\n",
    "Обычно нейросетки обучаются довольно долго. В связи с этим обучать их на различных фолдах и оценивать качество работы модели на кросс-валидации не очень быстрое занятие, которое себе может позволить далеко не каждый. Для проверки качества обычно внутри обучения с помощью параметра `validation_split` часть выборки оставляют под валидацию, которая осуществляется после каждой эпохи. Как только качество на валидации начнёт падать, это будет означать, что модель переобучилаcь. \n",
    "\n",
    "Всё, что будет нам возвращать метод `.fit`, мы запишем в переменную `hist`. После обученя модели там окажется вся история ошибок на каждом шаге обучения. Отключить сообщения о том, на каком этапе обучения в данный момент находится модель, можно с параметром `verbose = 0`. Переменную $y$ для успешного обучения сетки нужно будет перевести в матрицу из дамми-переменных с помощью команды `to_categorical`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JzjyeXqdE6lH",
    "outputId": "30bcba88-00fb-4d33-987a-ed2230ec4c55"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dSqvTLotE6lH",
    "outputId": "957ce03b-f1c5-429d-a2d9-a81a413c2682"
   },
   "outputs": [],
   "source": [
    "hist = model.fit(X_train, to_categorical(y_train), validation_split=0.2, epochs=30, verbose=1, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cIhDmPRJE6lH"
   },
   "outputs": [],
   "source": [
    "preds = tf.argmax(model.predict(X_train), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XJaahPB_g6_l",
    "outputId": "35c67434-55b5-4c44-914d-7e63ec01b75e"
   },
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vB4HVrSeE6lH"
   },
   "outputs": [],
   "source": [
    "acc = Accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o28oILUgE6lH",
    "outputId": "37f6f835-a725-43bc-e1aa-d66d8fc77e33"
   },
   "outputs": [],
   "source": [
    "acc(preds,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QjoDwOzHE6lH"
   },
   "source": [
    "Возвращает этот метод history — это история ошибок на каждом шаге обучения. Посмотрим на динамику ошибок нашей модели во времени. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "GsZo6XqyE6lH",
    "outputId": "0dd64bc1-e8cf-464e-fe88-c00bb410eec4"
   },
   "outputs": [],
   "source": [
    "start = 1\n",
    "plt.plot(hist.history['loss'][start:])\n",
    "plt.plot(hist.history['val_loss'][start:])\n",
    "plt.legend(['Train loss', 'Validation loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aTNnpuwfE6lH",
    "outputId": "4ca907c1-e619-42c9-ab68-1280792d0d1a"
   },
   "outputs": [],
   "source": [
    "# Можно предсказать вероятности для тестовой выборки\n",
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IbJrazpfE6lH",
    "outputId": "941f2f87-f839-47d2-85e6-c44ace4bab0c"
   },
   "outputs": [],
   "source": [
    "# А можно классы \n",
    "tf.argmax(model.predict(X_train), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PPNKwzpFE6lH"
   },
   "outputs": [],
   "source": [
    "# Можно найти logloss\n",
    "log_loss(y_test, model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PGi0EcN5E6lI"
   },
   "outputs": [],
   "source": [
    "# Можно сохранить модель\n",
    "model.save(\"weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o_RrUERdE6lI",
    "outputId": "4a4789fc-3401-4413-81f6-529edefe5798"
   },
   "outputs": [],
   "source": [
    "# Можно посмотреть на качество модели по всем указанным при коммпиляции метрикам. \n",
    "score = model.evaluate(X_test, to_categorical(y_test), verbose=0)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ENqe2FdPE6lI"
   },
   "source": [
    "Модель сходится довольно плохо. Функция потерь на валидации со временем начинает скакать. __Как думаете, с чем это связано?__\n",
    "\n",
    "----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2W_rqFORE6lI"
   },
   "source": [
    "__Ответ:__ Вспомним про такую замечательную штуку как нормализация и посмотрим насколько она улучшит скорость обучения и качество модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4AIyvrBvE6lI"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h6yjFtKtE6lI"
   },
   "source": [
    "Обучаем модель на нормализованных данных. Попробуем учить подольше. Так сказать: двойной удар по сходимости. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lHO2h3QME6lI"
   },
   "outputs": [],
   "source": [
    "model = get_new_model()  # Эпох стало 300 вместо 100\n",
    "hist = model.fit(X_train, to_categorical(y_train), validation_split=0.2, epochs=30, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "HDZm9wGXE6lI",
    "outputId": "09edca8e-dd7a-4abd-dd2d-e9fdc8be506e"
   },
   "outputs": [],
   "source": [
    "start = 0\n",
    "plt.plot(hist.history['loss'][start:])\n",
    "plt.plot(hist.history['val_loss'][start:])\n",
    "plt.legend(['Train loss', 'Validation loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oqQcwwPmE6lI",
    "outputId": "8e8a1e90-0579-4b8a-89b2-76bef3a78df7"
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, to_categorical(y_test), verbose=0)\n",
    "score "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HC1ekR_wE6lI"
   },
   "source": [
    "Качество нашей модели на валидационных данных достигает пика после определенного количества эпох, а затем начинает снижаться. Это происходит из-за того, что модель начинает __переобучаться.__ Очень важно знать способы как можно предотвратить это. Переобученая модель просто запоминает выборку. Нам бы хотелось, чтобы она обобщала закономерности и адекватно вела себа на новых данных.\n",
    "\n",
    "Обратным случаем переобучения является __недообучение.__ Оно возникает, когда все еще есть возможность улучшить показатели модели на проверочном наборе данных. Недообучение может произойти по разным причинам: например, если модель недостаточно сильная, или слишком сложная, или просто недостаточно тренировалась на данных. В любом случае это будет означать, что не были выучены основные паттерны из проверочного сета. Нам нужно найти золотую середину.\n",
    "\n",
    "Чтобы избежать переобучения, наиболее оптимальным решением будет использовать больше тренировочных данных. Модели, обученные на большем количестве данных, естественным образом обобщают их лучше. Если возможность раздобыть ещё данных исчерпана, можно использовать методы регуляризации. Они ограничивают количество и тип инофрмации, которые модель может хранить в себе. Если нейросеть может запомнить только небольшое количество паттернов, то тогда процесс оптимизации заставит ее сфокусироваться на самых важных, наиболее заметных шаблонах, которые будут иметь более высокий шанс обобщения. __Попробуем дать переобучению бой!__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gPF1aKPGE6lI"
   },
   "source": [
    "## Различные воспитательные трюки \n",
    "\n",
    "1. Начните с маленькой сети. Не забывайте прикидывать сколько наблдюдений $n$ тратится на оценку каждого из $k$ параметров. Если величина $\\frac{n}{k}$ очень маленькая, то не может идти речи об адекватных оценках параметров!  \n",
    "2. Всегда оставляйте часть выборки под валидацию на каждой эпохе.\n",
    "3. Усложняйте модель, пока качество на валидации не начнёт падать.\n",
    "4. Не забывайте проскалировать ваши наблюдения для лучшей сходимости. \n",
    "5. Можно попробовать ещё целую серию различных **трюков**: \n",
    "\n",
    "\n",
    "* __Архитектура нейросети__\n",
    "    * Больше/меньше нейронов\n",
    "    * Больше/меньше слоёв \n",
    "    * Другие функции активации (tanh, relu, leaky relu, elu etc) \n",
    "    * Регуляризация (dropout, l1,l2) \n",
    "\n",
    "\n",
    "* __Более качественная оптимизация__  \n",
    "    * Можно попробовать выбрать другой метод оптимизации \n",
    "    * Можно попробовать менять скорость обучения, моментум и др.\n",
    "    * Разные начальные значения весов\n",
    "\n",
    "\n",
    "* __Попробовать собрать больше данных__ \n",
    "* __Для случая картинок объёмы данных можно увеличить искусственно с помощью подхода, который называется Data augmemntation, но об этом позже__\n",
    "\n",
    "И это далеко не полный список. Обратите внимание, что делать grid_search для больших сеток это довольно времязатратное занятие... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fN3IzIQuE6lI"
   },
   "source": [
    "## 4. Эксперименты \n",
    "\n",
    "Наверняка, у каждого в голове возникла какая-то классная идея по улучшению нашей базовой архитектуры. Пора реализовать её! Если идей нет, попробуйте: \n",
    "\n",
    "- Поменять функции активации на elu или сигмоиды\n",
    "- Увеличить размер архитектуры \n",
    "\n",
    "Не забывайте сохранять историю обучения и закидывать её на наш график для сравнения. Когда надоест, посмотрите на итоговое качество модели на тесте. А то по валидации и переобучиться можно :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jBh6G2VcE6lI"
   },
   "outputs": [],
   "source": [
    "def get_new_model():\n",
    "    acc = Accuracy()\n",
    "\n",
    "    model = Sequential([\n",
    "        L.Dense(25, input_dim = X_train.shape[1], kernel_initializer='he_normal'),\n",
    "        L.Dropout(0.2),\n",
    "        L.Activation(tf.nn.relu),\n",
    "        L.Dense(25, kernel_initializer='he_normal', activation='ReLU'),\n",
    "        L.Dense(4, activation='softmax', kernel_initializer='random_normal')\n",
    "\n",
    "    ], name = 'First')  \n",
    "\n",
    "    optimizer = opt.Adam(lr=1e-3)\n",
    "\n",
    "    model.compile(loss = 'categorical_crossentropy', \n",
    "                  metrics=['acc'], \n",
    "                  optimizer=optimizer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_new_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(X_train, to_categorical(y_train), validation_split=0.2, epochs=30, verbose=1, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, to_categorical(y_test), verbose=0)\n",
    "score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "plt.plot(hist.history['loss'][start:])\n",
    "plt.plot(hist.history['val_loss'][start:])\n",
    "plt.legend(['Train loss', 'Validation loss'])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "gPF1aKPGE6lI"
   ],
   "name": "sem1_keras_intro_classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "mlearn",
   "language": "python",
   "name": "mlearn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "6eb9e1cf2af2cf6251f1c932a803c6b2f25b1e2cfa2de873853bae064510a498"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
